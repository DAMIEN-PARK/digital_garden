---
title: 발표_프로젝트
description: 
date:
  - - 2025-05-09
tags:
  - Project
publish: true
---
 
지금 말씀하신 구성요소를 바탕으로 **전체 흐름도(시스템 플로우) + 블록 구조화**를 먼저 제안드릴게요.

# 🔧 전체 프로젝트 흐름
### 1. **Unity (가상 공간 인터페이스)**
- 캐릭터가 마을을 자유롭게 이동
- 특정 집(예: 연구소 LAB)에 들어가면 이벤트 트리거 발생
    - ➝ n8n 또는 외부 시스템으로 연결
    - ➝ Streamlit 또는 브라우저 창 열림 (자동화 시스템 시각화)
### 2. **음성 인식 (Unity 내장)**
- 명령어 인식 → 이벤트 실행 (예: “보고서 생성해줘”, “일정 추가해줘”)
- 음성 입력 ➝ n8n → AI agent 실행 가능
### 3. **n8n (자동화 허브)**
- 음성 또는 이벤트 입력 → AI Agent 작동 → 다양한 처리
    - 일정 자동 등록
    - 웹/DB에서 데이터 수집
    - GPT API 호출 → 텍스트 요약/보고서 생성
    - 시각화 API 또는 Streamlit 호출
### 4. **RAG / Multimodal (Streamlit + OpenAI)**
- (선택적 사용) 문서 기반 질문응답, 이미지 기반 이해 등
- 현재는 구현 완료된 상태, 필요 시 RAG모듈만 호출 가능
### 5. **Agent 기반 자동화**
- 사용자의 목적을 판단하고 적절한 태스크 자동 선택
    - 예: "이번 주 보고서 준비해줘" → 데이터 수집 + 요약 + Streamlit 시각화

##  시스템 블록 구성 (개념도 형태)

```plaintext
[Unity] ---(이벤트 발생)---> [n8n Trigger]
                |
         [음성 인식 기능]
                |
        ▼                           ▼
[AI Agent 인식]           [Streamlit 시각화 호출]
     |                            |
[일정 추가 / 정보 수집 / 보고서 생성]
     |
[PostgreSQL 저장 또는 보고서 다운로드]
```

## 📝 지금 단계에서 필요한 것 정리

1. **n8n 전체 흐름을 시각화 및 정리**  
    ➝ 어떤 노드들이 있는지, 어디서 데이터를 받아 처리하는지 전체 맵핑  
    ➝ 필요하다면 함께 플로우차트 그려드릴 수 있음
2. **음성 입력 → n8n → AI agent 실행 자동화 플로우 정리**  
    ➝ 예: “내일 회의 일정 등록해줘” → n8n이 agent에게 task 전달
3. **Streamlit 또는 RAG 모듈을 agent와 유연하게 연결하는 구조**  
    ➝ 사용자가 명시하지 않아도 agent가 RAG 또는 시각화를 자동 판단하도록 설정
4. **PostgreSQL 연동 정확히 마무리**  
    ➝ 대화 기록, 사용자 요청, 생성된 보고서 등을 저장

## 다음 단계 제안
- **n8n 플로우 맵핑 도식** 먼
- 아니면 agent가 "사용자 목적"을 자동 판단하고 행동하는 흐름 먼저 정리할까요?

---
이미 구성하신 n8n 플로우는 꽤 잘 정리되어 있습니다.  
현재 구조를 바탕으로 **개선 포인트**, 그리고 **더 간결하게 표현할 수 있는 도식 예시**를 아래에 정리해드릴게요.

## 현재 플로우 핵심 요약 (분석 기반)

```
[트리거]  
 → [Chat 수신]  
    → [AI Agent 작동]  
        → OpenAI Chat Model  
        → Postgres Chat Memory  
        → If 조건 분기  
            → (True) 벡터스토어 QA 실행  
                → Supabase Vector Store + Embedding(OpenAI)
```


##  개선 포인트 3가지

### 1. **벡터스토어 의존도 줄이기**
- 현재는 조건문(`If`)에서 벡터스토어 쿼리를 따로 실행합니다.
- 하지만 **AI Agent에게 Retrieval Tool로 포함**시켜주면, 조건 분기 없이 자연스럽게 필요할 때만 벡터스토어를 활용하게 만들 수 있습니다.

> **개선 방법:**  
> `AI Agent` 노드에서 tools로 `"retrieval from vector store"`를 설정하고,  
> 해당 tool이 자동 호출되도록 설정.

### 2. **Postgres Chat Memory 위치 정리**
- 현재 `AI Agent` 노드에서 `Memory`로 연결되었지만,  
    사실상 Postgres에 저장하는 작업이 중요한 역할이라면 이걸 독립된 흐름으로 뺄 수 있습니다.
> **개선 방법:**  
> `AI Agent` → 응답 생성 후 → `Postgres Chat Memory 저장` 노드 추가  
> (선택적으로 삽입 메시지만 저장하거나, RAG 사용 여부 등도 같이 저장)

### 3. **Tool 사용 범위 명확히 정리**
- 지금은 `If` 분기문 이후만 vector store tool이 동작하므로,  
    다양한 tool (예: 일정 추가, 문서 요약 등)을 agent에게 주고 **tool router 패턴**을 도입하면 확장성이 더 좋아집니다.
> 예: "AI Agent → Tools Router (RAG, 요약, 일정추가, 시각화 등)"

## ✳️ 더 간결한 도식 (추천)
```plaintext
[When Test Button Clicked or Chat Received]
                ↓
           [AI Agent Node]
                ↓
      +------------------------+
      | Tool 1: RAG with Supabase (Vector)   |
      | Tool 2: Schedule Manager             |
      | Tool 3: Report Writer (Streamlit)   |
      | Tool 4: Voice Input Interpreter      |
      +------------------------+
                ↓
      [Save to Postgres Chat Memory]
```
- 벡터스토어도 “필요할 때만” agent가 알아서 사용하는 구조
- 새로운 기능도 Tool로 쉽게 추가 가능


## 다음 단계 추천
1. `AI Agent`에 **Tool 형태로 vector store retrieval 추가**  
    → 조건문(`If`) 없이 agent가 직접 판단하게 하기
2. 대화 이력 저장을 **별도 노드로 분리**하거나 조건적으로 저장할 수 있게 구성
3. 향후 확장 도구 (예: 일정관리, 보고서 작성)도 tool 목록에 포함 가능하게 구조 설계


필요하시면 이 간결 도식을 기준으로 **n8n에 적용 가능한 실제 노드 구조 템플릿**도 만들어 드릴 수 있습니다.  
어떤 부분부터 구체화하면 좋을까요?


좋습니다. 지금 프로젝트의 흐름과 목표(음성 + 에이전트 + 자동화)를 기반으로,  
**n8n에서 기능별 노드 구성 예시**를 아래와 같이 정리해드리겠습니다.
##  전체 플로우 개요
Unity → Chat 입력
      ↓
Chat Trigger ( [[Webhook]] or 메시지 수신)
      ↓
AI Agent ← (Tool 1 ~ Tool 4 자동 선택)
      ↓
Postgres Chat Memory (이력 저장)

## 🧩 기능별 Tool 구성 (n8n 노드 예시)

### **1. Tool 1: 문서 기반 질문 응답 (RAG)**

> 사용자가 "이 논문 내용 요약해줘", "이거 관련 문서 찾아줘"라고 말할 때
#### 구성 노드:
- Supabase Vector Store (vectorStore)
    
- Embeddings OpenAI
    
- Answer questions with a vector store
    
- 결과 → 메시지 응답 or 요약 저장
    
### **2. Tool 2: 일정 관리 자동화**

> 사용자가 "내일 오전 10시에 회의 있어", "일정 추가해줘"라고 말할 때
#### 구성 노드:
- Function 노드: 사용자 메시지에서 날짜/시간/내용 추출
    
- Google Calendar 노드 또는 PostgreSQL INSERT
    
- 확인 메시지 반환
 
#### 예시 함수 노드:

```javascript
return [{
  summary: "회의",
  startTime: "2025-05-10T10:00:00",
  endTime: "2025-05-10T11:00:00"
}]
```

### **3. Tool 3: 보고서 자동 생성**
> "지난주 회의 기록 정리해줘", "데이터 보고서 만들어줘"
#### 구성 노드:

- 데이터 수집 (API, DB)
    
- GPT 기반 요약 (OpenAI Completion)
    
- Markdown or HTML 생성 (Function 노드)
    
- Streamlit 서버 호출 (REST API 노드)
    
- 결과 URL 반환 or PDF 저장

### **4. Tool 4: 감정 로그 / 대화 분석 (확장 가능)**

> "내가 오늘 무슨 말을 많이 했어?", "내 톤이 어땠어?" 등

#### 구성 노드:

- Postgres Chat Memory 조회
    
- 감정 분석 모델 호출 (예: GPT + 감정프롬프트)
    
- 시각화 API 호출 or 결과 반환

## ✅ AI Agent 노드 설정 예시 (Tools 포함)

```json
{
  "type": "agent",
  "tools": [
    "RAG Vector QA",
    "Schedule Manager",
    "Report Generator",
    "Emotion Analyzer"
  ],
  "memory": "Postgres Chat Memory",
  "model": "OpenAI GPT-4"
}
```

## 🔁 대화 저장 흐름
- AI Agent 이후 → Postgres Chat Memory 노드에 `session_id`, `role`, `message`, `timestamp` 저장

## 🔄 유니티 연동 예시 흐름

```plaintext
[Unity 음성 명령: "일정 추가해줘"]  
→ [n8n Webhook 호출]  
→ [Chat Trigger]  
→ [AI Agent]  
→ [Tool 선택: Schedule Manager]  
→ [Google Calendar API 실행 or PostgreSQL 일정 저장]  
→ [응답: “일정 추가 완료했습니다”]
```

---

필요하시면 이 흐름을 기반으로 **n8n 내 실제 노드 구성 예시 템플릿(.json)** 형태도 만들어 드릴 수 있습니다.

다음으로 어떤 기능부터 구현하길 원하시나요?  
(예: 일정관리 → 보고서 → 음성명령 통합 등)


### Resources
